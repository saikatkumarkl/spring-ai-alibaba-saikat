models:
  - id: 1
    name: ollama-gpt-oss
    provider: ollama
    modelName: gpt-oss:120b-cloud
    baseUrl: http://localhost:11434
    apiKey: ollama
    status: 1
    defaultParameters:
      temperature: 0.7
      maxTokens: 4096
    supportedParameters:
      - name: temperature
        type: number
        minValue: 0
        maxValue: 2
        defaultValue: 0.7
        required: false
        description: Sampling temperature
      - name: maxTokens
        type: number
        minValue: 1
        maxValue: 8192
        defaultValue: 4096
        required: false
        description: Maximum output tokens
